{"cells":[{"cell_type":"markdown","metadata":{},"source":["PIP install function:"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: requests in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.7.4)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.1.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: python-dotenv in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.1)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.1.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: openai in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.35.11)\n","Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.4.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.8.2)\n","Requirement already satisfied: sniffio in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: certifi in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n","Requirement already satisfied: httpcore==1.* in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\patlacey\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n","Requirement already satisfied: colorama in c:\\users\\patlacey\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.1.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["%pip install requests\n","%pip install python-dotenv\n","%pip install openai"]},{"cell_type":"markdown","metadata":{},"source":["Imports libraries & load API Key"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["sk-sarah-v1zQsnpdM7XoXOawJmrJT3BlbkFJ4hLCy5TU2r5UrHJQniBj\n"]}],"source":["from dotenv import load_dotenv\n","from openai import OpenAI\n","import requests\n","# from functools import partial\n","# import concurrent.futures\n","import os\n","\n","\n","#Environment variables load from the .env file.\n","load_dotenv(\"sjapi.env\")\n","\n","#Print value of the OPENAI_API_KEY variable.\n","print(os.getenv(\"OPENAI_API_KEY\"))"]},{"cell_type":"markdown","metadata":{},"source":["Set up API client & create message list"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ChatCompletion(id='chatcmpl-9j96rAKMvid5gn7jy0zzH8DIMtLzk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Why couldn't the bicycle stand up by itself? Because it was two tired!\", role='assistant', function_call=None, tool_calls=None))], created=1720546805, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=25, total_tokens=41))\n","Response:\n","\n","Why couldn't the bicycle stand up by itself? Because it was two tired!\n","\n","\n","Total tokens used: 41\n"]}],"source":["#Connection to OpenAI API with API key.\n","client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n","\n","#Prompt for the user to enter a message.\n","prompt = input(\"Please enter a message: \")\n","\n","#List of messages to send ot the API. \n","message_list = [\n","    #The system message. Details can be added about how the model should respond.\n","    {\n","        \"role\": \"system\",\n","        \"content\": \"You're a very helpful Assistant. Thank you.\"\n","    },\n","    #The user message with the prompt that the model will respond to. \n","    {\n","        \"role\": \"user\",\n","        \"content\": prompt\n","    }\n","]\n","\n","'''Call the API'''\n","#This can make a chat completions API call to OpenAI.\n","#'response' contains the model's response to the prompt.\n","response = client.chat.completions.create(\n","    model='gpt-3.5-turbo', #model name\n","    messages=message_list, #messages list\n",")\n","\n","#Prints the whole response object with all teh details.\n","print(response)\n","\n","#Navigate through the response object to get model's response & tool tokens API call used.\n","print(f'Response:\\n\\n{response.choices[0].message.content}\\n\\n')\n","print(f'Total tokens used: {response.usage.total_tokens}')"]},{"cell_type":"markdown","metadata":{},"source":["Created functions & list of function descriptions."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'partial' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 31\u001b[0m\n\u001b[0;32m     26\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msjapi.env\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#Functions list to call with arguments\u001b[39;00m\n\u001b[0;32m     30\u001b[0m functions_to_call \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 31\u001b[0m     \u001b[43mpartial\u001b[49m(fetch_data_from_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://platform.openai.com/playground/chat?models=gpt-3.5-turbo-1106\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     32\u001b[0m     partial(calculate_factorial, \u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m     33\u001b[0m     partial(read_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msjapi.env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m     ]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Function to call other functions in parallel\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_functions_in_parallel\u001b[39m(functions):\n","\u001b[1;31mNameError\u001b[0m: name 'partial' is not defined"]}],"source":["#Fetching Data from a URL.\n","def fetch_data_from_url(url):\n","    response = requests.get(url)\n","    return f\"Data from {url}: {response.status_code}\"\n","\n","#Example URL\n","url = \"https://platform.openai.com/playground/chat?models=gpt-3.5-turbo-1106\"\n","\n","#Calculating Factorial.\n","def calculate_factorial(n):\n","    if n == 0 or n == 1:\n","        return 1\n","    else:\n","        result = 1\n","        for i in range(2, n + 1):\n","            result *= i  \n","        return f\"Factorial of {n}: {result}\"\n","\n","#Reading a File.\n","def read_file(file_path):\n","    with open(file_path, 'r') as file:\n","        data = file.read()\n","    #Return first 50 characters for brevity\n","    return f\"Contents of {file_path}: {data[:50]}...\"\n","\n","file_path = \"sjapi.env\"\n","\n","\n","'''\n","Up until here you are doing great! \n","Below you need to add a few things and make some changes:\n","\n","    1. Create the list of dictionaries that hold the natural language description of the functions available \n","    and how the arguments are connected to the function. (tools parameter) I think you were finishing this part up in class.\n","\n","    2. Make the chat completions API call using the API client you created earlier. Make sure to have the 4 parameters\n","    needed for function calling ability.\n","\n","    3. Append the API response (\"assistant\" message) to the message list and then run the functions the model picked \n","    and append the function result as the \"tool\" message.\n","\n","    4. Make the second API call. This only needs the 2 required parameters (model and the updated message list).\n","\n","\n","'''\n","#Functions list to call with arguments\n","\n","functions_to_call = [\n","    partial(fetch_data_from_url, \"https://platform.openai.com/playground/chat?models=gpt-3.5-turbo-1106\"),\n","    partial(calculate_factorial, 5),\n","    partial(read_file, \"sjapi.env\")\n","    ]\n","\n","# Function to call other functions in parallel\n","def call_functions_in_parallel(functions):\n","    with concurrent.futures.ThreadPoolExecutor() as executor:\n","        # Start the operations and mark each future with its function\n","        future_to_function = {executor.submit(fn): fn for fn in functions}\n","        results = []\n","        for future in concurrent.futures.as_completed(future_to_function):\n","            fn = future_to_function[future]\n","            try:\n","                result = future.result()\n","                results.append(result)\n","            except Exception as exc:\n","                results.append(f\"{fn.__name__} generated an exception: {exc}\")\n","    return results\n","\n","# Call the functions in parallel\n","results = call_functions_in_parallel(functions_to_call)\n","print(results)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
